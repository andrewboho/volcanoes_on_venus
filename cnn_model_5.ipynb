{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# fix dimension ordering issue\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "seed = 28\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-data rows: 7000, Train-data columns: 12100\n",
      "Train-labels rows: 7000, Train-labels columns: 4\n",
      "Test-data rows: 2734, Test-data columns: 12100\n",
      "Test-labels rows: 2734, Test-labels columns: 4\n"
     ]
    }
   ],
   "source": [
    "floydhub_dir = \"/floyd/input/volcanoes_venus\"\n",
    "\n",
    "# Load data - Floydhub\n",
    "data_train = pd.read_csv(\"/floyd/input/volcanoes_venus/train_images.csv\", header=None)\n",
    "labels_train = pd.read_csv(\"/floyd/input/volcanoes_venus/train_labels.csv\")\n",
    "data_test = pd.read_csv(\"/floyd/input/volcanoes_venus/test_images.csv\", header=None)\n",
    "labels_test = pd.read_csv(\"/floyd/input/volcanoes_venus/test_labels.csv\")\n",
    "\n",
    "# Load data - Local\n",
    "#data_train = pd.read_csv(\"data/train_images.csv\", header=None)\n",
    "#labels_train = pd.read_csv(\"data/train_labels.csv\")\n",
    "#data_test = pd.read_csv(\"data/test_images.csv\", header=None)\n",
    "#labels_test = pd.read_csv(\"data/test_labels.csv\")\n",
    "\n",
    "print(\"Train-data rows: {}, Train-data columns: {}\".format(data_train.shape[0], data_train.shape[1]))\n",
    "print(\"Train-labels rows: {}, Train-labels columns: {}\".format(labels_train.shape[0], labels_train.shape[1]))\n",
    "print(\"Test-data rows: {}, Test-data columns: {}\".format(data_test.shape[0], data_test.shape[1]))\n",
    "print(\"Test-labels rows: {}, Test-labels columns: {}\".format(labels_test.shape[0], labels_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New class distribution: 0.5\n",
      "X_train_up shape: (12000, 1, 110, 110)\n",
      "y_train_up shape: (12000,)\n",
      "X_test shape: (2734, 1, 110, 110)\n",
      "y_test shape: (2734,)\n"
     ]
    }
   ],
   "source": [
    "# Prep data for modeling\n",
    "X_train = np.array(data_train.values).astype(\"float32\")\n",
    "y_train = np.array(labels_train[\"Volcano?\"].values).astype(\"float32\")\n",
    "X_test = np.array(data_test.values).astype(\"float32\")\n",
    "y_test = np.array(labels_test[\"Volcano?\"].values).astype(\"float32\")\n",
    "\n",
    "# Shape to include channel dim for Conv2D\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 110, 110)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 110, 110)\n",
    "\n",
    "# Normalize input\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# Up-sample to balance target class\n",
    "X_upsampled, y_upsampled = resample(X_train[y_train == 1], y_train[y_train == 1], replace=True,\n",
    "                                   n_samples=X_train[y_train == 0].shape[0], random_state=seed)\n",
    "\n",
    "X_train_up = np.vstack((X_train[y_train == 0], X_upsampled))\n",
    "y_train_up = np.hstack((y_train[y_train == 0], y_upsampled))\n",
    "\n",
    "y_pred = np.zeros(y_train_up.shape[0])\n",
    "print(\"New class distribution:\", np.mean(y_pred == y_train_up))\n",
    "\n",
    "print(\"X_train_up shape:\", X_train_up.shape)\n",
    "print(\"y_train_up shape:\", y_train_up.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dim: (1, 110, 110)\n"
     ]
    }
   ],
   "source": [
    "input_dim = (X_train_up.shape[1], X_train_up.shape[2], X_train_up.shape[3])\n",
    "epochs = 30\n",
    "print(\"Input dim:\", input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_dim, output_dim, epochs=25, lrate=0.01):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=input_dim, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\", padding=\"same\",))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\",))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\",))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\", padding=\"same\",))\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    \n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\", padding=\"same\",))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(rate=0.2))\n",
    "    model.add(Dense(1024, activation=\"relu\", kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(512, activation=\"relu\", kernel_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(output_dim, activation=\"sigmoid\"))\n",
    "\n",
    "    decay = lrate / epochs\n",
    "    sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "    \n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 110, 110)      320       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 110, 110)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 110, 110)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 55, 55)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 55, 55)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 55, 55)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 55, 55)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 64, 27, 27)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 128, 27, 27)       73856     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128, 27, 27)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 128, 27, 27)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 128, 13, 13)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 21632)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              22152192  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 22,963,937\n",
      "Trainable params: 22,963,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(input_dim, 1, epochs=epochs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 2734 samples\n",
      "Epoch 1/30\n",
      "12000/12000 [==============================] - 36s 3ms/step - loss: 0.6933 - acc: 0.5108 - val_loss: 0.6923 - val_acc: 0.7772\n",
      "Epoch 2/30\n",
      "12000/12000 [==============================] - 32s 3ms/step - loss: 0.6927 - acc: 0.5118 - val_loss: 0.6826 - val_acc: 0.8413\n",
      "Epoch 3/30\n",
      "12000/12000 [==============================] - 32s 3ms/step - loss: 0.6907 - acc: 0.5385 - val_loss: 0.6919 - val_acc: 0.5644\n",
      "Epoch 4/30\n",
      "12000/12000 [==============================] - 32s 3ms/step - loss: 0.6768 - acc: 0.5993 - val_loss: 0.6979 - val_acc: 0.3453\n",
      "Epoch 5/30\n",
      "12000/12000 [==============================] - 32s 3ms/step - loss: 0.5769 - acc: 0.7281 - val_loss: 0.5444 - val_acc: 0.8285\n",
      "Epoch 6/30\n",
      "12000/12000 [==============================] - 32s 3ms/step - loss: 0.4788 - acc: 0.8032 - val_loss: 0.3401 - val_acc: 0.9144\n",
      "Epoch 7/30\n",
      "12000/12000 [==============================] - 32s 3ms/step - loss: 0.3126 - acc: 0.8787 - val_loss: 0.2362 - val_acc: 0.9331\n",
      "Epoch 8/30\n",
      "12000/12000 [==============================] - 32s 3ms/step - loss: 0.2563 - acc: 0.9032 - val_loss: 0.2919 - val_acc: 0.9012\n",
      "Epoch 9/30\n",
      "12000/12000 [==============================] - 32s 3ms/step - loss: 0.2193 - acc: 0.9151 - val_loss: 0.2058 - val_acc: 0.9375\n",
      "Epoch 10/30\n",
      "12000/12000 [==============================] - 32s 3ms/step - loss: 0.1955 - acc: 0.9292 - val_loss: 0.1994 - val_acc: 0.9382\n",
      "Epoch 11/30\n",
      "12000/12000 [==============================] - 32s 3ms/step - loss: 0.1717 - acc: 0.9355 - val_loss: 0.1758 - val_acc: 0.9422\n",
      "Epoch 12/30\n",
      "12000/12000 [==============================] - 32s 3ms/step - loss: 0.1503 - acc: 0.9441 - val_loss: 0.1598 - val_acc: 0.9495\n",
      "Epoch 13/30\n",
      "12000/12000 [==============================] - 32s 3ms/step - loss: 0.1306 - acc: 0.9519 - val_loss: 0.1335 - val_acc: 0.9568\n",
      "Epoch 14/30\n",
      "12000/12000 [==============================] - 32s 3ms/step - loss: 0.1074 - acc: 0.9631 - val_loss: 0.1280 - val_acc: 0.9579\n",
      "Epoch 15/30\n",
      "12000/12000 [==============================] - 32s 3ms/step - loss: 0.0814 - acc: 0.9713 - val_loss: 0.1097 - val_acc: 0.9660\n",
      "Epoch 16/30\n",
      "12000/12000 [==============================] - 32s 3ms/step - loss: 0.0719 - acc: 0.9740 - val_loss: 0.1182 - val_acc: 0.9601\n",
      "Epoch 17/30\n",
      "12000/12000 [==============================] - 32s 3ms/step - loss: 0.0583 - acc: 0.9783 - val_loss: 0.1236 - val_acc: 0.9605\n",
      "Epoch 18/30\n",
      "12000/12000 [==============================] - 32s 3ms/step - loss: 0.0497 - acc: 0.9841 - val_loss: 0.1172 - val_acc: 0.9660\n",
      "Epoch 19/30\n",
      "12000/12000 [==============================] - 32s 3ms/step - loss: 0.0344 - acc: 0.9888 - val_loss: 0.1114 - val_acc: 0.9744\n",
      "Epoch 20/30\n",
      "12000/12000 [==============================] - 31s 3ms/step - loss: 0.0381 - acc: 0.9874 - val_loss: 0.1066 - val_acc: 0.9766\n",
      "Epoch 21/30\n",
      "12000/12000 [==============================] - 31s 3ms/step - loss: 0.0259 - acc: 0.9918 - val_loss: 0.1028 - val_acc: 0.9748\n",
      "Epoch 22/30\n",
      "12000/12000 [==============================] - 31s 3ms/step - loss: 0.0227 - acc: 0.9923 - val_loss: 0.1100 - val_acc: 0.9759\n",
      "Epoch 23/30\n",
      "12000/12000 [==============================] - 31s 3ms/step - loss: 0.0227 - acc: 0.9924 - val_loss: 0.1187 - val_acc: 0.9770\n",
      "Epoch 24/30\n",
      "12000/12000 [==============================] - 31s 3ms/step - loss: 0.0146 - acc: 0.9951 - val_loss: 0.1106 - val_acc: 0.9773\n",
      "Epoch 25/30\n",
      "12000/12000 [==============================] - 31s 3ms/step - loss: 0.0156 - acc: 0.9954 - val_loss: 0.1176 - val_acc: 0.9748\n",
      "Epoch 26/30\n",
      "12000/12000 [==============================] - 31s 3ms/step - loss: 0.0185 - acc: 0.9944 - val_loss: 0.1126 - val_acc: 0.9751\n",
      "Epoch 27/30\n",
      "12000/12000 [==============================] - 31s 3ms/step - loss: 0.0159 - acc: 0.9954 - val_loss: 0.1161 - val_acc: 0.9762\n",
      "Epoch 28/30\n",
      "12000/12000 [==============================] - 31s 3ms/step - loss: 0.0134 - acc: 0.9962 - val_loss: 0.1107 - val_acc: 0.9744\n",
      "Epoch 29/30\n",
      "12000/12000 [==============================] - 31s 3ms/step - loss: 0.0114 - acc: 0.9973 - val_loss: 0.1193 - val_acc: 0.9777\n",
      "Epoch 30/30\n",
      "12000/12000 [==============================] - 31s 3ms/step - loss: 0.0106 - acc: 0.9963 - val_loss: 0.1089 - val_acc: 0.9762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb86db71d30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_up, y_train_up, validation_data=(X_test, y_test), epochs=epochs, batch_size=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 97.62%\n",
      "Baseline error rate: 2.38%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline accuracy: {:.2f}%\".format(100 * scores[1]))\n",
    "print(\"Baseline error rate: {:.2f}%\".format(100 * (1 - scores[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9762253108997806\n",
      "\n",
      "Confusion matrix:\n",
      "\n",
      "[[2269   31]\n",
      " [  34  400]]\n",
      "\n",
      "Classification report:\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      0.99      0.99      2300\n",
      "        1.0       0.93      0.92      0.92       434\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy:\", accuracy_score(y_test, preds))\n",
    "print(\"\\nConfusion matrix:\\n\")\n",
    "print(confusion_matrix(y_test, preds))\n",
    "print(\"\\nClassification report:\\n\")\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
